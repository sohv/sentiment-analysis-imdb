{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vX_HoYAJTGLv"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":624,"status":"ok","timestamp":1712230030663,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"ViADVk9HTebd"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2686,"status":"ok","timestamp":1712230035585,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"WVmA6Qq7Tm2u"},"outputs":[],"source":["# Now that we have our model, we need some good-quality data to work with, and this is precisely where the datasets library kicks in.\n","# In my case, I will use the Hugging Face datasets library to import a dataset containing tweets segmented by their sentiment (Positive, Neutral or Negative).\n","\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n","df = pd.DataFrame(dataset['train'])\n","\n","# The code begins by importing the load_dataset function from the datasets module.\n","# The load_dataset function is used to load a specific dataset from the Hugging Face's dataset hub.\n","# The dataset \"mteb/tweet_sentiment_extraction\" is loaded into the variable dataset.\n","# The pandas library is used to convert the loaded dataset into a DataFrame.\n","# The DataFrame is created from the 'train' portion of the dataset and stored in the variable df"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1712232433923,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"kwNkXwb1Tu2F","outputId":"99109998-a785-4b41-b848-ed859dc17b87"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                               text  label  \\\n","0      cb774db0d1                I`d have responded, if I were going      1   \n","1      549e992a42      Sooo SAD I will miss you here in San Diego!!!      0   \n","2      088c60f138                          my boss is bullying me...      0   \n","3      9642c003ef                     what interview! leave me alone      0   \n","4      358bd9e861   Sons of ****, why couldn`t they put them on t...      0   \n","...           ...                                                ...    ...   \n","27476  4eac33d1c0   wish we could come see u on Denver  husband l...      0   \n","27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...      0   \n","27478  f67aae2310   Yay good for both of you. Enjoy the break - y...      2   \n","27479  ed167662a5                         But it was worth it  ****.      2   \n","27480  6f7127d9d7     All this flirting going on - The ATG smiles...      1   \n","\n","      label_text  \n","0        neutral  \n","1       negative  \n","2       negative  \n","3       negative  \n","4       negative  \n","...          ...  \n","27476   negative  \n","27477   negative  \n","27478   positive  \n","27479   positive  \n","27480    neutral  \n","\n","[27481 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-109514bd-1125-48a0-beb4-ce0b623af14d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>label_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>1</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on Denver  husband l...</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>I`ve wondered about rake to.  The client has ...</td>\n","      <td>0</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>Yay good for both of you. Enjoy the break - y...</td>\n","      <td>2</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>2</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>All this flirting going on - The ATG smiles...</td>\n","      <td>1</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27481 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-109514bd-1125-48a0-beb4-ce0b623af14d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-109514bd-1125-48a0-beb4-ce0b623af14d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-109514bd-1125-48a0-beb4-ce0b623af14d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4ca8b8e0-5a22-4300-beb2-fc10e4a7371f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ca8b8e0-5a22-4300-beb2-fc10e4a7371f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4ca8b8e0-5a22-4300-beb2-fc10e4a7371f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_a9c81ff2-4c8e-4f26-bf5f-c1ee195596db\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_a9c81ff2-4c8e-4f26-bf5f-c1ee195596db button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 27481,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27481,\n        \"samples\": [\n          \"a7f72a928a\",\n          \"ef42dee96c\",\n          \"07d17131b1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27481,\n        \"samples\": [\n          \" WOOOOOOOOOO   are you coming to Nottingham at any point?  lovelovelove<3\",\n          \"resting had a whole day of walking\",\n          \"was in Palawan a couple of days ago, i`ll try to post pictures tom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":36}],"source":["df"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5709,"status":"ok","timestamp":1712230046518,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"4KZMvHKsT4lX"},"outputs":[],"source":["# Now that we already have our dataset, we need a tokenizer to prepare it to be parsed by our model.\n","# As LLMs work with tokens, we require a tokenizer to process the dataset.\n","# To process your dataset in one step, use the Datasets map method to apply a preprocessing function over the entire dataset.\n","# This is why the second step is to load a pre-trained Tokenizer and tokenize our dataset so it can be used for fine-tuning.\n","\n","from transformers import GPT2Tokenizer\n","\n","# Loading the dataset to train our model\n","dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","def tokenize_function(examples):\n","   return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","\n","small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n","small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n","\n","# The code starts by importing the GPT2Tokenizer from the transformers library.\n","# It then loads a dataset from \"mteb/tweet_sentiment_extraction\" using the load_dataset function.\n","# The GPT2Tokenizer is instantiated using a pretrained model \"gpt2\".\n","# The padding token for the tokenizer is set to be the same as the end of sentence (eos) token.\n","# A function tokenize_function is defined to tokenize the text in the examples using the GPT2 tokenizer.\n","# The function pads or truncates the tokenized text to a maximum length.\n","# The map function is used to apply the tokenize_function to the entire dataset in batches.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5905,"status":"ok","timestamp":1712230004622,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"94v0D9xrUQmT","outputId":"3f272be1-a782-41aa-8736-ad5f43832ab9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#Start by loading your model and specify the number of expected labels. From the Tweet’s sentiment dataset card, you know there are three labels:\n","\n","from transformers import GPT2ForSequenceClassification\n","\n","model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)\n","\n","#The code starts by importing the GPT2ForSequenceClassification class from the transformers library.\n","# This class is a part of the Hugging Face's transformers library, which provides models for NLP tasks.\n","# The GPT2ForSequenceClassification class is a GPT-2 model designed for sequence classification tasks.\n","# The second line of code initializes a GPT2ForSequenceClassification model with pre-trained weights.\n","# The \"gpt2\" argument tells the function to load the weights of the base GPT-2 model.\n","# The num_labels=3 argument specifies that the model should be configured to output predictions for three different labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FISJ3FoKU5yV"},"outputs":[],"source":["!pip install evaluate\n","!pip install numpy"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":609,"status":"ok","timestamp":1712229505567,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"UmCfezhDVgpp"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3012,"status":"ok","timestamp":1712230070971,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"},"user_tz":-330},"id":"AjJA51DjU257"},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","   logits, labels = eval_pred\n","   predictions = np.argmax(logits, axis=-1)\n","   return metric.compute(predictions=predictions, references=labels)\n","\n","#- The code starts by importing a module named 'evaluate'.\n","# It then loads an evaluation metric called 'accuracy' from the 'evaluate' module and assigns it to the variable 'metric'.\n","# A function named 'compute_metrics' is defined, which takes one argument 'eval_pred'.\n","# Inside the function, 'eval_pred' is unpacked into two variables: 'logits' and 'labels'.\n","# The 'np.argmax' function is used on 'logits' to find the indices of maximum values along the last axis, creating 'predictions'.\n","# The 'compute' method of 'metric' is called with 'predictions' and 'references' (which is 'labels') as arguments.\n","# The function 'compute_metrics' returns the result of the 'compute' method, which is the accuracy of the predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YB7gbsgoVEkL"},"outputs":[],"source":["!pip install accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYzE-3SqZBIX"},"outputs":[],"source":["!pip show accelerate"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"CfHjHuIEY6W-","executionInfo":{"status":"ok","timestamp":1712230886533,"user_tz":-330,"elapsed":812386,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"84937a68-67d6-40f9-f252-16f188690cb7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 13:28, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.035500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=750, training_loss=0.904355936686198, metrics={'train_runtime': 810.9145, 'train_samples_per_second': 3.7, 'train_steps_per_second': 0.925, 'total_flos': 1567794659328000.0, 'train_loss': 0.904355936686198, 'epoch': 3.0})"]},"metadata":{},"execution_count":11}],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","   output_dir=\"test_trainer\",\n","   #evaluation_strategy=\"epoch\",\n","   per_device_train_batch_size=1,  # Reduce batch size here\n","   per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n","   gradient_accumulation_steps=4\n","   )\n","\n","\n","trainer = Trainer(\n","   model=model,\n","   args=training_args,\n","   train_dataset=small_train_dataset,\n","   eval_dataset=small_eval_dataset,\n","   compute_metrics=compute_metrics,\n","\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","source":["trainer.save_model(\"/content/drive/MyDrive/sentiment_analysis\")"],"metadata":{"id":"kDtx0KPz6oV_","executionInfo":{"status":"ok","timestamp":1712231041809,"user_tz":-330,"elapsed":3222,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Doing evaluation\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    accuracy = (preds == labels).mean()\n","    return {\"accuracy\": accuracy}"],"metadata":{"id":"S2QWwUrr7VrK","executionInfo":{"status":"ok","timestamp":1712231123617,"user_tz":-330,"elapsed":424,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# Load the configuration from the saved model directory\n","with open(\"/content/drive/MyDrive/sentiment_analysis/config.json\", \"r\") as f:\n","    config = json.load(f)\n","\n","# Get the model name from the configuration\n","model_name = config[\"model_type\"]\n","print(\"Fine-tuned model name:\", model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nP7nJ3xz7_3T","executionInfo":{"status":"ok","timestamp":1712231328855,"user_tz":-330,"elapsed":474,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"c5a17172-f2c6-4001-fe8b-e902a94b16eb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Fine-tuned model name: gpt2\n"]}]},{"cell_type":"code","source":["import accelerate"],"metadata":{"id":"c_f77Prh8TDX","executionInfo":{"status":"ok","timestamp":1712231369194,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["fine_tuned_model = trainer.model"],"metadata":{"id":"j_IrkT0R8-xt","executionInfo":{"status":"ok","timestamp":1712231545975,"user_tz":-330,"elapsed":713,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","eval_trainer = Trainer(\n","    model=fine_tuned_model,  # Your fine-tuned model\n","    eval_dataset=small_eval_dataset  # Your evaluation dataset\n",")\n","fine_tuned_model.config.pad_token_id = 0\n","# Evaluate the model\n","evaluation_result = eval_trainer.evaluate()\n","\n","print(\"Evaluation results:\", evaluation_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"aQtihZOV7lFY","executionInfo":{"status":"ok","timestamp":1712231769392,"user_tz":-330,"elapsed":91001,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"9e57bd02-7572-45b3-c6d3-92c17fb16ef2"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 01:28]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation results: {'eval_loss': 1.580585241317749, 'eval_runtime': 90.4674, 'eval_samples_per_second': 11.054, 'eval_steps_per_second': 1.382}\n"]}]},{"cell_type":"code","source":["from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, pipeline\n","\n","# Load your fine-tuned sentiment analysis model\n","model_path = \"/content/drive/MyDrive/sentiment_analysis\"  # Path to your fine-tuned sentiment analysis model\n","\n","# Load the model explicitly\n","model = GPT2ForSequenceClassification.from_pretrained(model_path)\n","\n","# Load the GPT-2 tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")  # Assuming you are using the base GPT-2 model\n","\n","# Create the sentiment analysis pipeline with the loaded model and tokenizer\n","sentiment_analysis = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n","\n","# Example input tweet\n","input_tweet = \"I'm very fucked up\"\n","\n","# Perform sentiment analysis inference\n","sentiment_result = sentiment_analysis(input_tweet)\n","\n","# Mapping of string labels to sentiment classes\n","label_map = {'LABEL_0': \"negative\", 'LABEL_1': \"neutral\", 'LABEL_2': \"positive\"}  # Adjust this mapping based on your model's label mapping\n","\n","# Get the predicted label index\n","predicted_label_index = sentiment_result[0]['label']\n","\n","# Map the label index to its corresponding sentiment class\n","predicted_sentiment_class = label_map[predicted_label_index]\n","\n","# Output the sentiment prediction\n","print(\"Sentiment:\", predicted_sentiment_class)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9I-ZIb8_cM0","executionInfo":{"status":"ok","timestamp":1712233111588,"user_tz":-330,"elapsed":2140,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"5071c9a2-e89d-4ffb-9fdc-1fa73e4c62bd"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment: negative\n"]}]},{"cell_type":"markdown","source":["It appears that the predicted label index returned by the sentiment-analysis pipeline is in the format 'LABEL_2', which cannot be directly converted to an integer. This suggests that the labels returned by the pipeline are string representations of label names, rather than numerical indices.\n","\n","In this case, you'll need to adjust your label_map dictionary to map these string labels to their corresponding sentiment classes.\n","\n","Make sure to adjust the 'LABEL_0', 'LABEL_1', and 'LABEL_2' keys in the label_map dictionary according to the labels returned by your sentiment analysis pipeline. You may need to inspect the output of sentiment_result[0]['label'] to determine the exact label names returned by your model.\n","\n","By using string labels in your label_map dictionary, you can map the predicted label name to its corresponding sentiment class. Adjust the code based on the actual label names returned by your sentiment analysis pipeline."],"metadata":{"id":"5iTyRBkTDTGi"}},{"cell_type":"markdown","source":["The error you're encountering suggests that the predicted label index (predicted_label_index) is not present in your label_map dictionary. It seems like the predicted_label_index is being interpreted as a string ('LABEL_2') rather than an integer.\n","\n","To resolve this issue, you need to make sure that predicted_label_index is indeed an integer corresponding to the predicted label index. It's possible that the sentiment-analysis pipeline is returning labels in a different format than expected.\n","\n","You can try converting the predicted_label_index to an integer before using it to retrieve the sentiment class from the label_map dictionary.\n","\n","By converting predicted_label_index to an integer using the int() function, you ensure that it matches the keys in your label_map dictionary, which are integers representing label indices.\n","\n","If you continue to encounter issues, double-check the format of the output from the sentiment-analysis pipeline and make sure it matches the expected format for extracting the predicted label index. Adjust the code accordingly based on the actual output format."],"metadata":{"id":"Ak5aOs7-DNqb"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1nTUhShxXOnichNjy_iw638ZlvigF5Vtp","authorship_tag":"ABX9TyMwYBNBH/onDnO6G8sbudAT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}