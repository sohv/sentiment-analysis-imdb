{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1y-3fc6S3dKsewocfr5rM_1SWWJebtivK","authorship_tag":"ABX9TyMMo+vUCwGNSuEBHdYjH5GC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"beHQlxNYZxmF","executionInfo":{"status":"ok","timestamp":1717373127150,"user_tz":-330,"elapsed":3996,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"outputs":[],"source":["#Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","source":["# Downloading required NLTK tools\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgKHAQZOak6L","executionInfo":{"status":"ok","timestamp":1717373146678,"user_tz":-330,"elapsed":1052,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"64c71b21-c5da-4068-b7e0-0eab665bf58e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/imdb_dataset/imdb_dataset.csv')"],"metadata":{"id":"bcBkmiyraDwv","executionInfo":{"status":"ok","timestamp":1717373154183,"user_tz":-330,"elapsed":4419,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Preprocessing\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text):\n","    words = word_tokenize(text.lower())\n","    words = [lemmatizer.lemmatize(word) for word in words if word.isalpha()]\n","    words = [word for word in words if word not in stop_words]\n","    return ' '.join(words)\n","\n","df['review'] = df['review'].apply(preprocess_text)"],"metadata":{"id":"pIbesczfaGci","executionInfo":{"status":"ok","timestamp":1717373316289,"user_tz":-330,"elapsed":160596,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)"],"metadata":{"id":"n97dJmqHZ8OG","executionInfo":{"status":"ok","timestamp":1717373337890,"user_tz":-330,"elapsed":415,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Model training and evaluation\n","models = [\n","    ('SVM', SVC()),\n","    ('Naive Bayes', MultinomialNB()),\n","    ('Random Forest', RandomForestClassifier())\n","]\n","\n","best_accuracy = 0\n","best_model = None\n","best_model_name = None\n","\n","for name, model in models:\n","    pipeline = Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('clf', model)\n","    ])\n","    pipeline.fit(X_train, y_train)\n","    y_pred = pipeline.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"{name} Accuracy: {accuracy}\")\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_model = pipeline\n","        best_model_name = name\n","\n","print(f\"Best model: {best_model_name} with Accuracy: {best_accuracy}\")\n","print(\"Classification Report:\")\n","print(classification_report(y_test, best_model.predict(X_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJbWp5yqZ7PJ","executionInfo":{"status":"ok","timestamp":1717377460210,"user_tz":-330,"elapsed":4119067,"user":{"displayName":"Sohan Venkatesh","userId":"15216100183022662980"}},"outputId":"1a71969a-44a9-4634-9538-39501ecd8f45"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM Accuracy: 0.8989\n","Naive Bayes Accuracy: 0.8657\n","Random Forest Accuracy: 0.8539\n","Best model: SVM with Accuracy: 0.8989\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","    negative       0.91      0.88      0.90      4961\n","    positive       0.89      0.91      0.90      5039\n","\n","    accuracy                           0.90     10000\n","   macro avg       0.90      0.90      0.90     10000\n","weighted avg       0.90      0.90      0.90     10000\n","\n"]}]}]}